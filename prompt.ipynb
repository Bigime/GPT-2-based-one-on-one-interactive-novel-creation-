{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 프롬프트 생성 및 등장인물 변환기\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GOP0iuwLa7sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gliner\n",
        "!pip install python-mecab-ko\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "S7G9GKw-bSTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "charList = ['C001',\n",
        " 'C002',\n",
        " 'C003',\n",
        " 'C004',\n",
        " 'C005',\n",
        " 'C006',\n",
        " 'C007',\n",
        " 'C008',\n",
        " 'C009',\n",
        " 'C010',\n",
        " 'C011',\n",
        " 'C012',\n",
        " 'C013',\n",
        " 'C014',\n",
        " 'C015',\n",
        " 'C016',\n",
        " 'C017',\n",
        " 'C018',\n",
        " 'C019',\n",
        " 'C020',\n",
        " 'C021',\n",
        " 'C022',\n",
        " 'C023',\n",
        " 'C024',\n",
        " 'C025',\n",
        " 'C026',\n",
        " 'C027',\n",
        " 'C028',\n",
        " 'C029',\n",
        " 'C030',\n",
        " 'C031',\n",
        " 'C032',\n",
        " 'C033',\n",
        " 'C034',\n",
        " 'C035',\n",
        " 'C036',\n",
        " 'C037',\n",
        " 'C038',\n",
        " 'C039',\n",
        " 'C040',\n",
        " 'C041',\n",
        " 'C042',\n",
        " 'C043',\n",
        " 'C044',\n",
        " 'C045',\n",
        " 'C046',\n",
        " 'C047',\n",
        " 'C048',\n",
        " 'C049',\n",
        " 'C050',\n",
        " 'C051',\n",
        " 'C052',\n",
        " 'C053',\n",
        " 'C054',\n",
        " 'C055',\n",
        " 'C056',\n",
        " 'C057',\n",
        " 'C058',\n",
        " 'C059',\n",
        " 'C060',\n",
        " 'C061',\n",
        " 'C062',\n",
        " 'C063',\n",
        " 'C064',\n",
        " 'C065',\n",
        " 'C066',\n",
        " 'E001',\n",
        " 'E002',\n",
        " 'E003',\n",
        " 'E004',\n",
        " 'E005',\n",
        " 'E007',\n",
        " 'E009',\n",
        " 'E011',\n",
        " 'E025']"
      ],
      "metadata": {
        "id": "SdzAhY6CbSPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re\n",
        "\n",
        "#토큰들과 토크나이저 설정\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "SENT = \"<unused1>\"\n",
        "EOS = \"</s>\"\n",
        "BOS = \"</s>\"\n",
        "\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    bos_token=BOS,\n",
        "    eos_token=EOS,\n",
        "    unk_token=\"<unk>\",\n",
        "    pad_token=\"<pad>\",\n",
        "    mask_token=\"<unused0>\",\n",
        ")\n",
        "\n",
        "#토크나이저에 새로운 토큰 추가\n",
        "#등장인물들 새로운 토큰으로 추가하여 예외적으로 등장인물이 잘려서 토큰화되지 않도록 함\n",
        "\n",
        "koGPT2_TOKENIZER.add_tokens(charList)\n",
        "\n",
        "\n",
        "#Load your trained model\n",
        "#resize_token_embeddings를 명시해줘야 제대로 작동\n",
        "model_path = \"/content/drive/MyDrive/deepdaivproject/stage_emotion_final/storymaker_model.pth\" # Adjust the path to your saved model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "model.resize_token_embeddings(len(koGPT2_TOKENIZER))\n",
        "\n",
        "\n",
        "#저장된 커스텀 모델경로 복사\n",
        "checkpoint = torch.load(model_path)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"],strict=False)\n",
        "model.eval()\n",
        "\n",
        "#Interaction loop with the chatbot\n",
        "end = False\n",
        "with torch.no_grad():\n",
        "    conversation_history = []\n",
        "    num=0\n",
        "    while not end:\n",
        "        #if문은 처음 사용자가 문장을 입력했을 때\n",
        "        if num==0:\n",
        "          q = input(\"user > \").strip()\n",
        "          if q == \"quit\":\n",
        "              break\n",
        "          #사용자가 감정+대사 또는 서술 순으로 작성하기 때문에 학습한 패턴대로 토큰을 넣어주기\n",
        "          #위해서 문장을 쪼갬\n",
        "          q1 = q[0:2]\n",
        "          q2 = q[3:]\n",
        "          #학습했던 토큰의 순서대로 넣어줌\n",
        "          q = Q_TKN+q1+SENT+q2+SENT+A_TKN\n",
        "          #print(q)\n",
        "          gen_ids = model.generate(koGPT2_TOKENIZER.encode(q, return_tensors='pt'),\n",
        "                      max_length=256,\n",
        "                      pad_token_id=koGPT2_TOKENIZER.pad_token_id,\n",
        "                      eos_token_id=koGPT2_TOKENIZER.eos_token_id,\n",
        "                      bos_token_id=koGPT2_TOKENIZER.bos_token_id,\n",
        "                      use_cache=True,top_p=0.75,temperature=0.6,repetition_penalty=1.5,do_sample=True)\n",
        "          generated = koGPT2_TOKENIZER.decode(gen_ids[0],)\n",
        "          #print(generated)\n",
        "\n",
        "          #<sys>와 </s> 사이의 텍스트 추출\n",
        "          result = re.search(r\"<sys>(.*?)</s>\", generated)\n",
        "           # 결과 출력\n",
        "          if result:\n",
        "                generated = result.group(1).strip()\n",
        "                #<sys>와 </s> 사이의 텍스트만 추출하고 공백 제거\n",
        "          else:\n",
        "                print(\"해당 패턴을 찾을 수 없습니다.\")\n",
        "\n",
        "          #print(generated)\n",
        "          #1. 불필요한 태그 제거 (<unused1>, <sys>, </s> 등)\n",
        "          #cleaned_text = re.sub(r\"<unused1>|<sys>|</s>|<usr>|</s>\", \"\",generated)\n",
        "\n",
        "\n",
        "          #2. 불필요한 공백 제거할려고 했으나 공백이 있는 것이 토큰화에 유리하기 때문에 배제\n",
        "          #cleaned_text = cleaned_text.replace(\" \", \"\")\n",
        "          #print(cleaned_text)\n",
        "\n",
        "          #3 conversation_history에 추가\n",
        "          #사용자가 처음 문장을 입력했을 때에는 이전 문장이 존재하지 않으므로 현재 문장을 추가만 해준다.\n",
        "          conversation_history.append(generated)\n",
        "          #conversation_history.append('안녕하세요')\n",
        "          #print(conversation_history)\n",
        "\n",
        "\n",
        "          print(generated)\n",
        "          num+=1\n",
        "\n",
        "        #사용자가 작성한 문장이 처음이 아닐 때\n",
        "        else:\n",
        "          q = input(\"user > \").strip()\n",
        "          if q == \"quit\":\n",
        "             break\n",
        "          q1 = q[0:2]\n",
        "          q2 = q[3:]\n",
        "          #print(q1)\n",
        "          #print(q2)\n",
        "          #바로 이전 문장만 기억하게 할 것이기 때문에 pop 함수 사용해서 꺼내고 conversation_history list는 비어있도록 만듬\n",
        "          q3 = conversation_history.pop()\n",
        "          q3 = str(q3)\n",
        "          q = Q_TKN+q1+SENT+q3+q2+SENT+A_TKN\n",
        "          #print(q)\n",
        "          gen_ids = model.generate(koGPT2_TOKENIZER.encode(q, return_tensors='pt'),\n",
        "                      max_length=512,\n",
        "                      pad_token_id=koGPT2_TOKENIZER.pad_token_id,\n",
        "                      eos_token_id=koGPT2_TOKENIZER.eos_token_id,\n",
        "                      bos_token_id=koGPT2_TOKENIZER.bos_token_id,\n",
        "                      use_cache=True,top_p=0.85,temperature=0.6, repetition_penalty = 1.5 ,do_sample=True)\n",
        "\n",
        "          generated = koGPT2_TOKENIZER.decode(gen_ids[0],)\n",
        "          #print(generated)\n",
        "          #<sys>와 </s> 사이의 텍스트 추출\n",
        "          result = re.search(r\"<sys>(.*)</s>\", generated)\n",
        "\n",
        "          #결과 출력\n",
        "          if result:\n",
        "                generated = result.group(1).strip()  # <sys>와 </s> 사이의 텍스트만 추출\n",
        "          else:\n",
        "                print(\"해당 패턴을 찾을 수 없습니다.\")\n",
        "\n",
        "          #<sys>와 </s> 사이의 텍스트만 추출하면 special token 존재하지 않기 때문에 special token 제거과정은 생략\n",
        "          #generated = re.sub(r\"<pad>\", r\"\", generated)\n",
        "          #generated = re.sub(r\"<sys>\",r\"\",generated)\n",
        "          #generated = re.sub(r\"<unused0>\",r\"\",generated)\n",
        "          #generated = re.sub(r\"<unused1>\",r\"\",generated)\n",
        "          #generated = re.sub(r\"</s>\",r\"\",generated)\n",
        "          a = \"Bot > \"\n",
        "          print(a + generated)\n",
        "\n",
        "          #서사구조 자르기\n",
        "          #con_generated = generated[0:2]\n",
        "          #서사구조 자른 문장 conversation_history에 저장\n",
        "          conversation_history.append(q2+generated)\n",
        "          #print(conversation_history)"
      ],
      "metadata": {
        "id": "lFquHBUlbSNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "name_df = pd.read_csv('name.csv파일경로') #name.csv 파일 다운받고 경로 복사\n",
        "name_df"
      ],
      "metadata": {
        "id": "LJgAs0_rbSKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "charNameList = name_df['char'].to_list()\n",
        "nameList = name_df['이름'].to_list()\n",
        "\n",
        "tup_list = list(zip(charNameList, nameList))\n",
        "\n",
        "char_to_name = dict(tup_list)\n",
        "name_to_char = {v: k for k, v in char_to_name.items()}\n",
        "\n",
        "print(len(char_to_name))\n",
        "print(len(name_to_char))"
      ],
      "metadata": {
        "id": "uw0LnJEQbSIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "\n",
        "NERmodel = GLiNER.from_pretrained(\"taeminlee/gliner_ko\")"
      ],
      "metadata": {
        "id": "DxY5a-AObSRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_input_char_transformer(input):\n",
        "  tta_labels = [\"PERSON\"]\n",
        "  entities = NERmodel.predict_entities(input, tta_labels)\n",
        "  person_entities = [entity for entity in entities if entity['label'] == 'PERSON']\n",
        "\n",
        "  print(person_entities)\n",
        "\n",
        "  for idx, entity in enumerate(person_entities):\n",
        "    for name in name_to_char.keys():\n",
        "      if name in entity['text']:\n",
        "        entity['text'] = entity['text'].replace(name, name_to_char[name])\n",
        "\n",
        "        diff = len(name_to_char[name]) - len(name)\n",
        "        for en in person_entities[idx+1:]:\n",
        "          en['start'] += diff\n",
        "          en['end'] += diff\n",
        "\n",
        "        print(person_entities)\n",
        "        break\n",
        "\n",
        "  for entity in person_entities:\n",
        "    input = input[:entity['start']] + entity['text'] + input[entity['end']:]\n",
        "\n",
        "  return input\n",
        "\n",
        "def model_output_char_transformer(input):\n",
        "  for char in charList:\n",
        "    input = input.replace(char, char_to_name[char])\n",
        "\n",
        "  return input"
      ],
      "metadata": {
        "id": "BUqFo3sFbSCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio로 구현"
      ],
      "metadata": {
        "id": "muQuwq6FeL2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_chars = input(\"사용할 등장인물의 이름을 적으세요(띄어쓰기로 구분) > \").strip()\n",
        "user_chars_list = user_chars.split()\n",
        "\n",
        "print(user_chars_list)\n",
        "\n",
        "for index, user_char in enumerate(user_chars_list):\n",
        "  if user_char in name_to_char.keys():\n",
        "    temp_char = name_to_char[user_char] # E056 - 민수\n",
        "    print(temp_char)\n",
        "    temp_name = char_to_name[charList[index]] # 서연 - C003\n",
        "    print(temp_name)\n",
        "\n",
        "    name_to_char[user_char] = charList[index]\n",
        "    name_to_char[temp_name] = temp_char\n",
        "\n",
        "    char_to_name[charList[index]] = user_char\n",
        "    char_to_name[temp_char] = temp_name\n",
        "\n",
        "  else:\n",
        "    temp_name = char_to_name[charList[index]] # 성희 - C002\n",
        "    print(temp_name)\n",
        "\n",
        "    del char_to_name[charList[index]]\n",
        "    char_to_name[charList[index]] = user_char\n",
        "\n",
        "    del name_to_char[temp_name]\n",
        "    name_to_char[user_char] = charList[index]"
      ],
      "metadata": {
        "id": "aGXUID7abR8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "whole_story = \"\"\n",
        "last_sent = \"\"  # 마지막 입력과 출력된 문장 저장\n",
        "previous_story = \"\"  # 바로 전 문장을 제외한 스토리 저장\n",
        "previous_input_output = \"\"  # 바로 전 입력과 출력된 문장 저장\n",
        "\n",
        "def storymaker(input, emo, struct, regenerate=False):\n",
        "    global whole_story\n",
        "    global last_sent\n",
        "    global previous_story\n",
        "    global previous_input_output  # 바로 전 입력과 생성된 문장을 저장하는 변수\n",
        "\n",
        "    if regenerate:\n",
        "        # regenerate 시 바로 전에 생성된 문장과 입력만 사용\n",
        "        story_context = previous_input_output + input  # 이전 입력/출력 + 새 입력\n",
        "        whole_story = previous_story  # 이전 스토리로 복원\n",
        "        whole_story += input  # 새로 입력한 문장을 whole_story에 추가\n",
        "    else:\n",
        "        if input == 'quit' or input == '가을이었다.':\n",
        "            return '종료합니다.' + '\\n' + whole_story\n",
        "\n",
        "        previous_story = whole_story  # 현재까지의 스토리를 저장\n",
        "        whole_story += input  # 새로운 입력을 whole_story에 반영\n",
        "\n",
        "        # 이전 입력과 출력된 문장 저장\n",
        "        previous_input_output = last_sent\n",
        "\n",
        "        # 문장을 생성할 때 바로 이전의 입력과 생성된 출력만 사용\n",
        "        story_context = last_sent + input\n",
        "        input = model_input_char_transformer(input)  # 입력 변환\n",
        "\n",
        "    # 입력 문장 + 감정 + 서사 구조 정보를 기반으로 문장 생성\n",
        "    q = Q_TKN + emo+ SENT + struct + SENT + story_context + SENT + A_TKN\n",
        "\n",
        "    gen_ids = model.generate(tokenizer.encode(q, return_tensors='pt'),\n",
        "                        max_length=256,\n",
        "                         temperature=0.3,\n",
        "                         top_p=0.75,\n",
        "                        # top_k=50,\n",
        "                        do_sample=True,\n",
        "                        repetition_penalty=2.0,\n",
        "                        pad_token_id=tokenizer.pad_token_id,\n",
        "                        eos_token_id=tokenizer.eos_token_id,\n",
        "                        bos_token_id=tokenizer.bos_token_id,\n",
        "                        use_cache=True)\n",
        "\n",
        "    generated = tokenizer.decode(gen_ids[0])\n",
        "    generated = generated.split(A_TKN)[1]\n",
        "    generated = generated.split(EOS)[0]\n",
        "\n",
        "    generated = model_output_char_transformer(generated)\n",
        "    whole_story += generated + \"\\n\"\n",
        "\n",
        "    last_sent = input + generated  # 마지막 입력 문장과 생성된 문장 저장\n",
        "\n",
        "    return whole_story, generated\n",
        "\n",
        "def show_whole_story():\n",
        "    return whole_story\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    story_state = gr.State(whole_story)  # 스토리를 상태로 저장\n",
        "    last_sent_state = gr.State(last_sent)  # 마지막 문장을 상태로 저장\n",
        "    previous_story_state = gr.State(previous_story)  # 이전 스토리 상태 저장\n",
        "    previous_input_output_state = gr.State(previous_input_output)  # 이전 입력/출력 저장\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"AI와 소설 만들기\")\n",
        "    with gr.Row():\n",
        "        input_text = gr.Textbox(label=\"입력\", placeholder=\"가을이었다.\")\n",
        "    with gr.Row():\n",
        "        struct_choice = gr.Radio(\n",
        "            [\"발단\", \"전개\", \"위기\", \"절정\", \"결말\"], label=\"서사 구조 단계\", info=\"다음 문장으로 나왔으면 하는 문장의 서사 구조 단계를 선택하세요.\"\n",
        "        )\n",
        "        emo_choice = gr.Radio(\n",
        "            [\"무덤덤\", \"동요\", \"관심\", \"슬픔\", \"분노\", \"행복\"], label=\"감정\", info=\"다음 문장으로 나왔으면 하는 문장의 감정을 선택하세요.\"\n",
        "        )\n",
        "\n",
        "    # 전체 스토리를 보여주는 텍스트 박스\n",
        "    whole_story_output = gr.Textbox(label=\"전체 스토리\", placeholder=\"지금까지의 이야기가 여기에 표시됩니다.\", interactive=False)\n",
        "\n",
        "    def generate_story(messages, input_text, emo_choice, struct_choice, regenerate, whole_story, last_sent, previous_story, previous_input_output):\n",
        "        story, generated = storymaker(input_text, emo_choice, struct_choice, regenerate)\n",
        "\n",
        "        # 다시 생성일 경우 이전 AI 응답 삭제\n",
        "        if regenerate:\n",
        "            # 마지막 AI 메시지를 삭제\n",
        "            if len(messages) > 0:\n",
        "                messages.pop(-1)  # 마지막 AI 메시지 제거\n",
        "                messages.pop(-1)  # 마지막 사용자 입력 제거\n",
        "\n",
        "        # 사용자 입력과 AI의 새 출력 추가\n",
        "        messages.append((input_text,None))\n",
        "        messages.append((None,generated))\n",
        "\n",
        "        return messages, story, last_sent, previous_story, previous_input_output\n",
        "\n",
        "    generate_button = gr.Button(\"생성\")\n",
        "    regenerate_button = gr.Button(\"다시 생성\")\n",
        "    whole_story_button = gr.Button('전체 스토리')\n",
        "\n",
        "    generate_button.click(generate_story,\n",
        "                          [chatbot, input_text, emo_choice, struct_choice, gr.State(False), story_state, last_sent_state, previous_story_state, previous_input_output_state],\n",
        "                          [chatbot, story_state, last_sent_state, previous_story_state, previous_input_output_state])\n",
        "\n",
        "    regenerate_button.click(generate_story,\n",
        "                            [chatbot, input_text, emo_choice, struct_choice, gr.State(True), story_state, last_sent_state, previous_story_state, previous_input_output_state],\n",
        "                            [chatbot, story_state, last_sent_state, previous_story_state, previous_input_output_state])\n",
        "\n",
        "    # 전체 스토리 버튼 클릭 시 전체 스토리 출력\n",
        "    whole_story_button.click(show_whole_story, [], whole_story_output)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "tKnSbsEMbRmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}